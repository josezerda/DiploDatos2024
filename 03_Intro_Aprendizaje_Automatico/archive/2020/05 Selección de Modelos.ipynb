{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Selección de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Definimos datos de lenguaje natural de juguete y vectorizamos el input usando bolsas de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "    ('chinese beijing chinese', 'zh'),\n",
    "    ('chinese chinese shangai', 'zh'),\n",
    "    ('chinese macao', 'zh'),\n",
    "    ('chinese beijing tokyo', 'zh'),\n",
    "    ('chinese beijing osaka', 'zh'),\n",
    "    ('tokyo japan chinese', 'ja'),\n",
    "    ('tokyo japan osaka', 'ja'),\n",
    "    ('osaka', 'ja'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_docs = np.array([doc for doc, _ in training])\n",
    "y = np.array([cls for _, cls in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(X_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada\n",
    "\n",
    "- [Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División K-Fold\n",
    "\n",
    "Podemos usar [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) para hacer cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4, shuffle=False, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    print(f\"TRAIN: {train_index} VAL: {val_index} {y_val}\")\n",
    "\n",
    "    #model.fit(X_train, y_train)\n",
    "    #model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División K-Fold Estratificada\n",
    "\n",
    "Para que la división sea estratificada, usamos [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=False, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    print(f\"TRAIN: {train_index} VAL: {val_index} {y_val}\")\n",
    "\n",
    "    #model.fit(X_train, y_train)\n",
    "    #model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda en Grilla (Grid Search)\n",
    "\n",
    "- [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla de Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos listar todas las combinaciones para usarlas a mano con [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(params)\n",
    "    model = DecisionTreeClassifier(**params, random_state=0)\n",
    "    #model.fit(...)\n",
    "    #model.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla de Parámetros + Validación Cruzada\n",
    "\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) nos sirve para hacer validación cruzada sobre una grilla de parámetros. Sklearn se encarga de todo el proceso y nos devuelve una tabla de resultados y el mejor clasificador obtenido.\n",
    "\n",
    "La búsqueda se puede configurar de varias maneras. Por defecto la validación cruzada es estratificada.\n",
    "\n",
    "- [scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "cv = GridSearchCV(model, param_grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cv.cv_results_\n",
    "params = results['params']\n",
    "mean = results['mean_test_score']\n",
    "std = results['std_test_score']\n",
    "rank = results['rank_test_score']\n",
    "\n",
    "print(\"crit.\\tdepth\\t| mean\\tstd\\trank\")\n",
    "for p, m, s, r in zip(params, mean, std, rank):\n",
    "    print(f\"{p['criterion']}\\t{p['max_depth']}\\t| {m:0.2f}\\t{s:0.2f}\\t{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_criterion', 'param_max_depth', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plot_tree(best_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla Aleatorizada\n",
    "\n",
    "- [Randomized Parameter Optimization](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils.fixes import loguniform\n",
    "from scipy import stats\n",
    "\n",
    "param_dist = {\n",
    "    'loss': [\n",
    "        'hinge',        # SVM\n",
    "        'log',          # logistic regression\n",
    "        #'preceptron',  # perceptron (not supported)\n",
    "    ],\n",
    "    'alpha': stats.loguniform(1e-4, 1e0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos muestrear mano con [ParameterSampler](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "for params in ParameterSampler(param_dist, 4, random_state=0):\n",
    "    print(params)\n",
    "    model = SGDClassifier(**params, random_state=0)\n",
    "    #model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla Aleatorizada + Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos dejar que Sklearn se encargue de todo con [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = SGDClassifier(random_state=0)\n",
    "\n",
    "cv = RandomizedSearchCV(model, param_dist, n_iter=10, cv=3)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = cv.cv_results_\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_alpha', 'param_alpha', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
